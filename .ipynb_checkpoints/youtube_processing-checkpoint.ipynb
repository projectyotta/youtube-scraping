{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scrapetube in c:\\programdata\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from scrapetube) (2.24.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->scrapetube) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->scrapetube) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->scrapetube) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->scrapetube) (3.0.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n",
      "The system cannot find the path specified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in c:\\programdata\\anaconda3\\lib\\site-packages (1.14.43)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.43 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3) (1.17.43)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.18.0,>=1.17.43->boto3) (0.15.2)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version != \"3.4\" in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.18.0,>=1.17.43->boto3) (1.25.9)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.18.0,>=1.17.43->boto3) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.43->boto3) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "# use library to get list of videos newly uploaded by a specific user \n",
    "!pip install scrapetube\n",
    "!pip install boto3\n",
    "import scrapetube\n",
    "import re \n",
    "import json \n",
    "import time    \n",
    "# get list of channels needed from config file or whatever from dropbox \n",
    "# send message via twilio to ensure message can be sent over \n",
    "# channels = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.youtube.com/c/unitednations\n",
    "https://www.youtube.com/c/WION\\\n",
    "https://www.youtube.com/c/Vikinged\n",
    "https://www.youtube.com/channel/UCFexD7T2S9PNpxQ1ejdKwwg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos_list(url,limit=200):\n",
    "    import re\n",
    "    videos = list(scrapetube.get_channel(url=url,limit=limit))\n",
    "    output = []\n",
    "    for i in range(0,len(videos)):\n",
    "        x = videos[i]\n",
    "        temp = {}\n",
    "        temp['images'] = [item['url'] for item in x['thumbnail']['thumbnails']]\n",
    "        temp['url'] = 'https://www.youtube.com/watch?v=' + x['videoId']\n",
    "        temp['title'] = x['title']['runs'][0]['text']\n",
    "        \n",
    "        try:\n",
    "            temp['channel_name'] = str(re.findall('([a-zA-Z ]*)\\d*.*', x['title']['accessibility']['accessibilityData']['label'].split('by')[1])[0]).strip()\n",
    "        except Exception as ex:\n",
    "            temp['channel_name']=''\n",
    "        try:\n",
    "            temp['duration'] = x['thumbnailOverlays'][0]['thumbnailOverlayTimeStatusRenderer']['text']['simpleText']        \n",
    "        except Exception as ex:\n",
    "            temp['duration'] = ''\n",
    "        try:\n",
    "            temp['when_published'] = x['publishedTimeText']['simpleText']\n",
    "        except Exception as ex:\n",
    "            temp['when_published'] = ''\n",
    "        try:\n",
    "            temp['view_count'] = x['viewCountText']['simpleText']\n",
    "        except Exception as ex:\n",
    "            temp['view_count'] = ''\n",
    "                \n",
    "        output.append(temp)\n",
    "    return output\n",
    "# idx = 'UC4woSp8ITBoYDmjkukhEhxg'\n",
    "# a = get_videos_list(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final.json') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object get_channel at 0x000002208D2354A0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_videos_list(url=\"https://www.youtube.com/c/unitednations\")\n",
    "\n",
    "# scrapetube.get_channel.__code__.co_varnames\n",
    "\n",
    "a = scrapetube.get_channel(\"UCFexD7T2S9PNpxQ1ejdKwwg\")\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in a:\n",
    "    print(str(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial data pull \n",
    "i = 0 \n",
    "for channel in channels:\n",
    "    x = get_videos_list(channel)\n",
    "    i = i+1 \n",
    "    print(str(i) + channel)\n",
    "    with open('youtube_initial_data/'+channel+'.json', 'w') as f:\n",
    "        json.dump(x, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge into single file \n",
    "import glob\n",
    "read_files = glob.glob(\"C:\\\\Users\\\\Administrator\\\\Desktop\\\\youtube_initial_data\\\\*.json\")\n",
    "final = []\n",
    "for item in read_files:\n",
    "    final.extend(json.load(open(item)))\n",
    "\n",
    "# cleanup \n",
    "with open('youtube_initial_data/'+'final'+'.json', 'w') as f:\n",
    "        json.dump(final, f)\n",
    "import os \n",
    "for item in read_files:\n",
    "    os.remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build logic to push existing data to a database - fuck it , S3 it is . \n",
    "# build logic to continually ingest data \n",
    "# build logic to store channel list as a config file somewhere \n",
    "\n",
    "import boto3 \n",
    "\n",
    "s3 = boto3.resource(service_name='s3',region_name='us-east-2',\n",
    "                    aws_access_key_id=access,\n",
    "                    aws_secret_access_key=secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google-drive-backup-pictures\n",
      "youtube-scraping\n"
     ]
    }
   ],
   "source": [
    "# for bucket in s3.buckets.all():\n",
    "#     print(bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s3.Bucket('youtube-scraping').upload_file(Filename='final.json', Key='final.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same concept for reading in config files from anywhere \n",
    "# Same logic will be used everywhere in multiple places \n",
    "# !pip install dropbox\n",
    "import dropbox\n",
    "class dbox_data:\n",
    "    \n",
    "    # instantiate dropbox object \n",
    "    \n",
    "    def __init__(self,dropbox_access_token=None,dbx=None):\n",
    "        self.dropbox_access_token = 'ADD_ACCESS_TOKEN_HERE'\n",
    "        self.dbx = dropbox.Dropbox(self.dropbox_access_token)\n",
    "        print('dropbox object created')\n",
    "    \n",
    "    # Get list of all the files present in the config folder \n",
    "    def get_list_of_files(self,path=''):\n",
    "        print('Getting list of files')\n",
    "        files = []\n",
    "        for entry in self.dbx.files_list_folder(path).entries:\n",
    "            files.append(dict({'is_downloadable': entry.is_downloadable , 'name': entry.name,  'path_display':entry.path_display}))\n",
    "        print('List of files ' + json.dumps(files))\n",
    "        return files\n",
    "\n",
    "    # Choose list of files which match the filename that you are feeding in \n",
    "    def choose_files(self,filename):\n",
    "        a = [item for item in self.get_list_of_files() if filename in item['name']]\n",
    "        print('List of filtered files ' + str(a))\n",
    "        return a \n",
    "    \n",
    "    # \n",
    "    def get_content(self,filename):\n",
    "        metadata, res = self.dbx.files_download(path=self.choose_files(filename)[0]['path_display'])\n",
    "        print('Content extracted from object is ' + str(res.text))\n",
    "        return res.text\n",
    "\n",
    "a = dbox_data().get_content(filename='aaa')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
